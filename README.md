# DISCLAIMER

Any actions and or activities related to the material contained within this repo is solely your responsibility. The misuse of the information in this repo can result in criminal charges brought against the company in question. The author will not be held responsible in the event any criminal charges be brought against any individuals misusing the information in this repo to break the law.

As written in [Linkedin User Agreement](https://www.linkedin.com/legal/user-agreement): **you agree you will not use**
    
   - bots or other automated methods to access the Services, add or download contacts, send or redirect messages.
   
### Terms And Conditions:

- I do not promote, encourage, support or excite any illegal activity or hacking without written permission in general. The repo and author of the repo is no way responsible for any misuse of the information.
- "linkedin-web-scraper" is just a terms that represents the name of the repo and is not a repo that provides any illegal information.
- This repo is totally meant for providing information on Computer Software, Computer Programming and other related topics.
- The Software's and Scripts provided by the repo should only be used for education purposes. The repo or the author can not be held responsible for the misuse of them by the users.
- I am not responsible for any direct or indirect damage caused due to the usage of the code provided on this site. All the information provided on this repo are for educational purposes only.

# LinkedIn Web Scraper

Python Web Scraper for LinkedIn companies. The script fully simulate an human activity in order to get data from LinkedIn web pages. The purpose is store data from companies of a certain zone, such as:

- Name 
- Overview 
- Size
- Website link
- Industry
- etc.

After collected the above information, these will be stored into an .xls file.

### Demo

[![Watch the video](https://img.youtube.com/vi/TKkJEo-4NTg/maxresdefault.jpg)](https://youtu.be/TKkJEo-4NTg)

# Usage

First of all, donwload the web driver you prefer (Firefox or Chrome) and put it inside the folder. Then put you credential inside the **config.ini** file and specify the web driver you donwloaded. Also others kind of parameters can be setted. 

The method *get_companies_name(...)* requires a link (in this case a link of a company) and will return an array of links in which each link is the page of the company.

After that, you can run *retrive_data(...)* that requires the array with the links and the name of the .xls file in which you want to store information that will be collected from each link for each company. 

Class *ManageExcelFile* will handle the I/O operation for the .xls file.

# Issues

It could happen that, after the loggin phase, LinkedIn could ask you to perform some operations instead of rediricet you to the feed (https://www.linkedin.com/feed/) page. 

In this case just:
  1. Stop the script
  2. Log with a browser in your account
  3. Skip the required operation
  4. Re-run the code

# Utility

- [Chrome Webdriver](https://chromedriver.chromium.org/downloads)
- [Selenium](https://selenium-python.readthedocs.io/installation.html)
- [Scrapy](https://docs.scrapy.org/en/latest/intro/tutorial.html)
